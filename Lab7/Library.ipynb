{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d12a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n",
      "ERROR: Could not find a version that satisfies the requirement mediapipe (from versions: none)\n",
      "ERROR: No matching distribution found for mediapipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\thaku\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\thaku\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\thaku\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# 4ml_fixed_timers.py\n",
    "!pip install cv2\n",
    "!pip install mediapipe\n",
    "!pip install numpy\n",
    "!pip install sounddevice\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98637d1-7a41-4ac5-b3d7-3efee494c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n",
      "ERROR: Could not find a version that satisfies the requirement mediapipe (from versions: none)\n",
      "ERROR: No matching distribution found for mediapipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\thaku\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\thaku\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\thaku\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\thaku\\anaconda3\\lib\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# 4ml_fixed_timers.py\n",
    "!pip install cv2\n",
    "!pip install mediapipe\n",
    "!pip install numpy\n",
    "!pip install sounddevice\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef23a5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 4ml_fixed_timers.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msounddevice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "# 4ml_fixed_timers.py\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CALIB_SECONDS = 3.0\n",
    "EAR_BLINK_THRESHOLD = 0.18\n",
    "BLINK_CONSEC_FRAMES = 2\n",
    "FACE_DET_CONF = 0.45\n",
    "EYE_VARIANCE_THRESHOLD = 200.0   # occlusion check: variance too low => likely covered\n",
    "EYE_MEAN_DARK = 45.0             # occlusion check: mean too dark => covered\n",
    "GAZE_X_DELTA = 0.07              # threshold around calibrated center for LEFT/RIGHT\n",
    "GAZE_Y_DELTA = 0.06              # threshold around calibrated center for UP/DOWN\n",
    "SCORE_SMOOTH = 6\n",
    "NOISE_SENSITIVITY = 2.0          # how much above baseline RMS counts as noise\n",
    "AUDIO_CALIB_SECONDS = 1.0\n",
    "AUDIO_SR = 22050\n",
    "AUDIO_BLOCKSIZE = 1024\n",
    "EYES_CLOSED_SECONDS = 3.0        # <-- display eyes closed if closed for this long\n",
    "NO_FACE_SECONDS = 10.0           # <-- exit if no face detected this many seconds\n",
    "# ----------------------------------------\n",
    "\n",
    "# MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.4)\n",
    "\n",
    "# landmark indices\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "LEFT_IRIS = 468\n",
    "RIGHT_IRIS = 473\n",
    "\n",
    "# audio globals (thread-safe)\n",
    "_audio_rms = 0.0\n",
    "_audio_lock = threading.Lock()\n",
    "_audio_stream = None\n",
    "_audio_baseline = 1e-6\n",
    "\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    global _audio_rms\n",
    "    mono = np.mean(indata, axis=1) if indata.ndim > 1 else indata[:,0]\n",
    "    rms = float(np.sqrt(np.mean(np.square(mono))))\n",
    "    with _audio_lock:\n",
    "        _audio_rms = rms\n",
    "\n",
    "def start_audio():\n",
    "    global _audio_stream\n",
    "    try:\n",
    "        _audio_stream = sd.InputStream(callback=audio_callback,\n",
    "                                       blocksize=AUDIO_BLOCKSIZE,\n",
    "                                       samplerate=AUDIO_SR,\n",
    "                                       channels=1)\n",
    "        _audio_stream.start()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Audio stream start failed:\", e)\n",
    "        return False\n",
    "\n",
    "def calibrate_audio_baseline():\n",
    "    global _audio_baseline\n",
    "    try:\n",
    "        print(f\"Calibrating microphone for {AUDIO_CALIB_SECONDS:.1f}s — please be quiet...\")\n",
    "        rec = sd.rec(int(AUDIO_CALIB_SECONDS * AUDIO_SR), samplerate=AUDIO_SR, channels=1, dtype='float64')\n",
    "        sd.wait()\n",
    "        mono = rec[:,0]\n",
    "        _audio_baseline = max(1e-6, float(np.sqrt(np.mean(np.square(mono)))))\n",
    "        print(f\"Audio baseline RMS = {_audio_baseline:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Audio calibration failed:\", e)\n",
    "        _audio_baseline = 1e-6\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def eye_aspect_ratio(landmarks, eye_indices, w, h):\n",
    "    try:\n",
    "        pts = [(landmarks[i].x * w, landmarks[i].y * h) for i in eye_indices]\n",
    "        A = np.linalg.norm(np.array(pts[1]) - np.array(pts[5]))\n",
    "        B = np.linalg.norm(np.array(pts[2]) - np.array(pts[4]))\n",
    "        C = np.linalg.norm(np.array(pts[0]) - np.array(pts[3]))\n",
    "        if C <= 1e-6:\n",
    "            return 0.0\n",
    "        return (A + B) / (2.0 * C)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def eye_region_stats(gray, landmarks, eye_indices, w, h, pad=6):\n",
    "    xs = [int(landmarks[i].x * w) for i in eye_indices]\n",
    "    ys = [int(landmarks[i].y * h) for i in eye_indices]\n",
    "    x1 = max(min(xs) - pad, 0); x2 = min(max(xs) + pad, w-1)\n",
    "    y1 = max(min(ys) - pad, 0); y2 = min(max(ys) + pad, h-1)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    region = gray[y1:y2, x1:x2]\n",
    "    if region.size == 0:\n",
    "        return None\n",
    "    return float(np.mean(region)), float(np.var(region))\n",
    "\n",
    "def get_iris_avg(landmarks):\n",
    "    try:\n",
    "        return (landmarks[LEFT_IRIS].x + landmarks[RIGHT_IRIS].x) / 2.0, \\\n",
    "               (landmarks[LEFT_IRIS].y + landmarks[RIGHT_IRIS].y) / 2.0\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def compute_concentration(gaze_ok, head_ok, blink_recent, occluded, noise_flag):\n",
    "    # weights (tunable): gaze 40%, head 30%, blink penalty 20%, noise 10%\n",
    "    gaze_score = 1.0 if gaze_ok else 0.0\n",
    "    head_score = 1.0 if head_ok else 0.0\n",
    "    blink_pen = 0.0 if not blink_recent else 0.5\n",
    "    noise_pen = 1.0 if noise_flag else 0.0\n",
    "    base = 0.4*gaze_score + 0.3*head_score + 0.2*(1.0 - blink_pen) + 0.1*(1.0 - noise_pen)\n",
    "    if occluded:\n",
    "        base *= 0.2\n",
    "    return int(np.clip(base * 100.0, 0, 100))\n",
    "\n",
    "# ---------- Start audio thread and calibrate ----------\n",
    "audio_ok = start_audio()\n",
    "if audio_ok:\n",
    "    calibrate_audio_baseline()\n",
    "else:\n",
    "    print(\"Warning: audio disabled; noise detection will be off.\")\n",
    "\n",
    "# ---------- Camera and calibration ----------\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"ERROR: Cannot open camera. Close other apps or check device.\")\n",
    "    raise SystemExit\n",
    "\n",
    "cv2.namedWindow(\"Concentration Tracker\", cv2.WINDOW_NORMAL)\n",
    "print(\"Camera opened. Starting gaze calibration — look straight at the camera now.\")\n",
    "\n",
    "calib_x = []\n",
    "calib_y = []\n",
    "calib_start = time.time()\n",
    "while time.time() - calib_start < CALIB_SECONDS:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    det = face_detection.process(rgb)\n",
    "    mesh = face_mesh.process(rgb)\n",
    "    if mesh.multi_face_landmarks and det.detections:\n",
    "        landmarks = mesh.multi_face_landmarks[0].landmark\n",
    "        avgx, avgy = get_iris_avg(landmarks)\n",
    "        if avgx is not None:\n",
    "            calib_x.append(avgx); calib_y.append(avgy)\n",
    "    cv2.putText(frame, \"Calibrating gaze (keep eyes on camera)...\", (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)\n",
    "    cv2.imshow(\"Concentration Tracker\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        raise SystemExit\n",
    "\n",
    "if not calib_x:\n",
    "    print(\"Calibration failed: no face/iris detected. Retry with better lighting/position.\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    raise SystemExit\n",
    "\n",
    "baseline_x = float(np.mean(calib_x))\n",
    "baseline_y = float(np.mean(calib_y))\n",
    "print(f\"Calibration complete. Baseline iris center = ({baseline_x:.3f}, {baseline_y:.3f})\")\n",
    "\n",
    "# ---------- Main variables ----------\n",
    "score_buf = deque(maxlen=SCORE_SMOOTH)\n",
    "frame_no = 0\n",
    "blink_frames = 0\n",
    "last_blink_time = 0.0\n",
    "BLINK_MIN_SEP = 0.35  # seconds between blink events\n",
    "\n",
    "# --- Timers we add (initialized here so they're in scope) ---\n",
    "eyes_closed_start = None\n",
    "no_face_start = None\n",
    "\n",
    "print(\"Tracker running. Press 'q' in the window to quit.\")\n",
    "\n",
    "# ---------- Main loop ----------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Frame grab failed; exiting main loop.\")\n",
    "        break\n",
    "\n",
    "    frame_no += 1\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # face detection confidence and mesh\n",
    "    det = face_detection.process(rgb)\n",
    "    mesh = face_mesh.process(rgb)\n",
    "    face_conf = 0.0\n",
    "    if det.detections:\n",
    "        face_conf = max([d.score[0] for d in det.detections])\n",
    "\n",
    "    occluded = False\n",
    "    blink_event = False\n",
    "    gaze_dir = \"UNKNOWN\"\n",
    "    concentration = 0\n",
    "\n",
    "    if mesh.multi_face_landmarks and face_conf >= FACE_DET_CONF:\n",
    "        # Reset no-face timer since we have a face now\n",
    "        no_face_start = None\n",
    "\n",
    "        lm = mesh.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # draw lightweight mesh\n",
    "        mp_drawing.draw_landmarks(frame, mesh.multi_face_landmarks[0], mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                  mp_drawing.DrawingSpec(color=(0,200,0), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(0,150,255), thickness=1))\n",
    "\n",
    "        # EAR blink detection (temporal)\n",
    "        left_ear = eye_aspect_ratio(lm, LEFT_EYE, w, h)\n",
    "        right_ear = eye_aspect_ratio(lm, RIGHT_EYE, w, h)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        if avg_ear > 0 and avg_ear < EAR_BLINK_THRESHOLD:\n",
    "            blink_frames += 1\n",
    "        else:\n",
    "            if blink_frames >= BLINK_CONSEC_FRAMES:\n",
    "                now = time.time()\n",
    "                if now - last_blink_time > BLINK_MIN_SEP:\n",
    "                    blink_event = True\n",
    "                    last_blink_time = now\n",
    "            blink_frames = 0\n",
    "\n",
    "        # --- NEW: Eyes closed continuous timer (3 seconds) ---\n",
    "        if avg_ear > 0 and avg_ear < EAR_BLINK_THRESHOLD:\n",
    "            if eyes_closed_start is None:\n",
    "                eyes_closed_start = time.time()\n",
    "            # else: keep the start time\n",
    "            # we do not change detection logic, just show overlay when time passes threshold\n",
    "            if time.time() - eyes_closed_start >= EYES_CLOSED_SECONDS:\n",
    "                cv2.putText(frame, \"EYES CLOSED > 3s\", (20, 270),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        else:\n",
    "            eyes_closed_start = None\n",
    "\n",
    "        # Occlusion: check pixel stats inside eye regions\n",
    "        left_stats = eye_region_stats(gray, lm, LEFT_EYE, w, h)\n",
    "        right_stats = eye_region_stats(gray, lm, RIGHT_EYE, w, h)\n",
    "        if left_stats is None or right_stats is None:\n",
    "            occluded = True\n",
    "        else:\n",
    "            lmean, lvar = left_stats; rmean, rvar = right_stats\n",
    "            if (lvar < EYE_VARIANCE_THRESHOLD or lmean < EYE_MEAN_DARK) and \\\n",
    "               (rvar < EYE_VARIANCE_THRESHOLD or rmean < EYE_MEAN_DARK):\n",
    "                occluded = True\n",
    "\n",
    "        # gaze using iris avg and calibrated baseline\n",
    "        avgx, avgy = get_iris_avg(lm)\n",
    "        if avgx is None:\n",
    "            gaze_dir = \"UNKNOWN\"\n",
    "        else:\n",
    "            dx = avgx - baseline_x\n",
    "            dy = avgy - baseline_y\n",
    "            # assign direction\n",
    "            if abs(dx) <= GAZE_X_DELTA and abs(dy) <= GAZE_Y_DELTA:\n",
    "                gaze_dir = \"CENTER\"\n",
    "            elif abs(dx) > abs(dy):\n",
    "                gaze_dir = \"LEFT\" if dx < 0 else \"RIGHT\"\n",
    "            else:\n",
    "                gaze_dir = \"UP\" if dy < 0 else \"DOWN\"\n",
    "\n",
    "        # head center heuristic (nose)\n",
    "        try:\n",
    "            nose = lm[1]\n",
    "            nose_x = nose.x; nose_y = nose.y\n",
    "            head_ok = (abs(nose_x - 0.5) < 0.22 and abs(nose_y - 0.5) < 0.18)\n",
    "        except Exception:\n",
    "            head_ok = False\n",
    "\n",
    "        # audio noise check (normalized)\n",
    "        with _audio_lock:\n",
    "            current_rms = _audio_rms\n",
    "        noise_flag = False\n",
    "        if _audio_baseline > 0 and current_rms > _audio_baseline * NOISE_SENSITIVITY:\n",
    "            noise_flag = True\n",
    "\n",
    "        # compute concentration\n",
    "        gaze_ok = (gaze_dir == \"CENTER\")\n",
    "        concentration = compute_concentration(gaze_ok, head_ok, blink_event, occluded, noise_flag)\n",
    "    else:\n",
    "        # no reliable face\n",
    "        concentration = 0\n",
    "        occluded = True\n",
    "        gaze_dir = \"NO_FACE\"\n",
    "        noise_flag = False\n",
    "\n",
    "        # --- NEW: Start/advance no-face timer; exit after threshold ---\n",
    "        if no_face_start is None:\n",
    "            no_face_start = time.time()\n",
    "        else:\n",
    "            elapsed_no_face = time.time() - no_face_start\n",
    "            # optional: draw countdown on frame so user knows\n",
    "            cv2.putText(frame, f\"No face: {int(elapsed_no_face)}s/{int(NO_FACE_SECONDS)}s\", (20, 270),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if elapsed_no_face >= NO_FACE_SECONDS:\n",
    "                print(f\"No face detected for {NO_FACE_SECONDS} seconds. Exiting...\")\n",
    "                break\n",
    "\n",
    "    # Reset no_face_start if face is present (handled above at detection start)\n",
    "    # (nothing else to do here)\n",
    "\n",
    "    score_buf.append(concentration)\n",
    "    smooth_score = int(np.mean(score_buf)) if len(score_buf) > 0 else concentration\n",
    "\n",
    "    # status label priority\n",
    "    if not mesh.multi_face_landmarks or face_conf < FACE_DET_CONF:\n",
    "        status = \"NO FACE\"\n",
    "    elif occluded:\n",
    "        status = \"OCCLUDED\"\n",
    "    else:\n",
    "        # noisy has precedence if noise present\n",
    "        with _audio_lock:\n",
    "            curr = _audio_rms\n",
    "        noisy = (_audio_baseline > 0 and curr > _audio_baseline * NOISE_SENSITIVITY)\n",
    "        if noisy:\n",
    "            status = \"NOISY\"\n",
    "        elif blink_event:\n",
    "            status = \"BLINK\"\n",
    "        elif smooth_score < 55:\n",
    "            status = \"DISTRACTED\"\n",
    "        else:\n",
    "            status = \"CONCENTRATED\"\n",
    "\n",
    "    # Draw UI\n",
    "    bar_x, bar_y, bar_w, bar_h = 18, 22, 320, 30\n",
    "    fill = int((smooth_score/100.0) * bar_w)\n",
    "    color = (0,200,0) if smooth_score >= 60 else (0,140,255) if smooth_score >= 40 else (0,80,200)\n",
    "    cv2.rectangle(frame, (bar_x, bar_y), (bar_x+bar_w, bar_y+bar_h), (30,30,30), -1)\n",
    "    cv2.rectangle(frame, (bar_x, bar_y), (bar_x+fill, bar_y+bar_h), color, -1)\n",
    "    cv2.rectangle(frame, (bar_x, bar_y), (bar_x+bar_w, bar_y+bar_h), (200,200,200), 2)\n",
    "    cv2.putText(frame, f\"{smooth_score}%\", (bar_x+bar_w+10, bar_y+22), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Status: {status}\", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"Gaze: {gaze_dir}\", (20, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    if blink_event:\n",
    "        cv2.putText(frame, \"BLINK\", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "    if noise_flag:\n",
    "        cv2.putText(frame, \"NOISE\", (20, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Frame: {frame_no}\", (20, 230), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,200), 1)\n",
    "\n",
    "    cv2.imshow(\"Concentration Tracker\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "try:\n",
    "    if _audio_stream is not None:\n",
    "        _audio_stream.stop()\n",
    "        _audio_stream.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Exited cleanly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d62cd0-280e-4213-8ad4-d30bd19ce495",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ All libraries imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"MediaPipe version:\", mp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba49d0fc-f253-4e73-9310-b53dbe5eb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement mediapipe==0.10.14 (from versions: none)\n",
      "ERROR: No matching distribution found for mediapipe==0.10.14\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe==0.10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837be46-79bc-4c15-b92c-b9853bd1dad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
